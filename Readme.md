### Принятие решения
Для тестового задания возьмем блог на JS, cделаем fork и развернем *для демонстрации* в self-hosted кластере.
Исходный код приложения, которое будем разворачивать в кластере
[тут](https://github.com/4volodin/startbootstrap-clean-blog)

Приложение смотрим тут: [Блог для тестового задания развернутый в кластере](https://mindbox.truedev.ru)

1. ##### Mультизональный кластер (три зоны), в котором пять нод.

Значит используем managed Kubernetes, например в AWS
зона - это набор датацентров, поэтому логично для стабильности и отказоустойчивости использовать мультизональный кластер, если одна зона отправится на обслуживание(теоретически предположив) - в дело вступают пункты SLA :). 

Хорошая архитектура - это продуманная и обговоренная на "берегу" для достижения SLA. 
Поэтому *best practice* - это приложения в разных зонах(ДЦ). Правда не всегда это экономически выгодно, бюджет решает и все зависит от конкретного проекта.

2. ##### Приложение требует около 5-10 секунд для инициализации

Добавим Probe кратно 5 сек и повесим на порт нашего приложения внутри контейнера, первая через 5с, потом 3 попытки каждая через 5c и reload если неудачно


3. ##### По результатам нагрузочного теста известно, что 4 пода справляются с пиковой нагрузкой

Задействуем горизонтальный автоскейлер, зададим порог в 75% и реплики с 1 до 4

4. ##### На первые запросы приложению требуется значительно больше ресурсов CPU, в дальнейшем потребление ровное в районе 0.1 CPU. По памяти всегда в районе 128M memory

Настраиваем лимиты в деплое CPU 0.1 memory 128M

5. ##### Приложение имеет дневной цикл по нагрузке – ночью запросов на порядки меньше, пик – днём

Простое известное мне решение по кронджобу создастся контейнер и будет управлять HPA в назначенное время(существует варианты, учитывая внешние метрики скейлиться или по eventам в кластере - в планах)

6. ##### Хотим максимально отказоустойчивый deployment

Внедряем podAntiAffinity - идея описана в [1ом пункте](#mультизональный-кластер-три-зоны-в-котором-пять-нод) 

7. ##### Хотим минимального потребления ресурсов
Используем HPA, настроим через metrics, что более тонко, хотя можно было и через targetCPUUtilizationPercentage, targetMemUtilizationPercentage

### Cобираем тестовый стенд
Напишем Dockerfile(прикрепил) для этого приложения

#### на техсобесе можно будет сборку причесать под best practice и убрать захардкоженные значения в переменные
```
docker build -t blog .

# проверим образ на сервере и удалим потом
docker run -name blog -p 3000:3000 blog
docker rmi blog

docker tag blog:latest 10.100.1.2:5000/blog:latest
docker push 10.100.1.2:5000/blog:latest

# проверим что наш образ запушился
curl -X GET -u <REGISTRY_USER>:<REGISTRY_PASS> http://10.100.1.2:5000/v2/_catalog
```

```
kubectl create namespace blogjs
kubectl create secret docker-registry my-registry-secret-mindbox \
--docker-server=10.100.1.2:5000 \
--docker-username=<REGISTRY_USER> \
--docker-password=<REGISTRY_PASS> \
--namespace=blogjs
kubectl apply -f app.yml
```

### На техническом собеседовании вместе улучшим наше приложение:
- оптимизируем образы
- уберем захардкоженные переменные
- прикрутим CI\CD для этого процесса
- проведем канареечное тестирование
- helm 
- ...
